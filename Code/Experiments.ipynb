{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-28T17:34:23.781995Z",
     "iopub.status.busy": "2025-01-28T17:34:23.781712Z",
     "iopub.status.idle": "2025-01-28T17:34:28.170439Z",
     "shell.execute_reply": "2025-01-28T17:34:28.169508Z",
     "shell.execute_reply.started": "2025-01-28T17:34:23.781974Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install transformers datasets torch scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T17:34:28.171704Z",
     "iopub.status.busy": "2025-01-28T17:34:28.171441Z",
     "iopub.status.idle": "2025-01-28T17:34:38.303194Z",
     "shell.execute_reply": "2025-01-28T17:34:38.302581Z",
     "shell.execute_reply.started": "2025-01-28T17:34:28.171680Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from transformers import BertModel,BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import random\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T17:34:38.305037Z",
     "iopub.status.busy": "2025-01-28T17:34:38.304519Z",
     "iopub.status.idle": "2025-01-28T17:34:38.308288Z",
     "shell.execute_reply": "2025-01-28T17:34:38.307527Z",
     "shell.execute_reply.started": "2025-01-28T17:34:38.305012Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T17:34:38.309497Z",
     "iopub.status.busy": "2025-01-28T17:34:38.309301Z",
     "iopub.status.idle": "2025-01-28T17:34:39.094170Z",
     "shell.execute_reply": "2025-01-28T17:34:39.093510Z",
     "shell.execute_reply.started": "2025-01-28T17:34:38.309479Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/nlp-cleaned/cleaned_dataset.csv')\n",
    "stop_words = set(stopwords.words('romanian'))\n",
    "def preprocess_review(review):\n",
    "    # Normalize the text font\n",
    "    review = unicodedata.normalize('NFKC', review)\n",
    "    # Replace inconsistent characters\n",
    "    review = review.replace('“', '\"').replace('”', '\"')\n",
    "    review = review.replace('ş', 'ș').replace(\"Ş\", \"Ș\").replace('ţ', 'ț').replace(\"Ţ\", \"Ț\")\n",
    "    # Remove links\n",
    "    review = re.sub(r'https?://\\S+', '', review)\n",
    "    # Remove included english reviews\n",
    "    rev_beginning = [\"english review:\", \"english:\", \"[english]\"]\n",
    "    indices = [review.lower().find(b) for b in rev_beginning]\n",
    "    if indices[0] != -1:\n",
    "        index = indices[0]\n",
    "    elif indices[1] != -1:\n",
    "        index = indices[1]\n",
    "    elif indices[2] != -1:\n",
    "        index = indices[2]\n",
    "    else:\n",
    "        index = -1\n",
    "    review = review[:index]\n",
    "\n",
    "    return review\n",
    "\n",
    "df['review'] = df['review'].apply(preprocess_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T17:34:39.095064Z",
     "iopub.status.busy": "2025-01-28T17:34:39.094864Z",
     "iopub.status.idle": "2025-01-28T17:34:39.104669Z",
     "shell.execute_reply": "2025-01-28T17:34:39.104056Z",
     "shell.execute_reply.started": "2025-01-28T17:34:39.095046Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split data into train and validation \n",
    "x_train, x_validation, y_train, y_validation = train_test_split(\n",
    "    df['review'], df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def downsample():\n",
    "    size = df['label'].value_counts().min()\n",
    "    \n",
    "    new_df = pd.DataFrame()\n",
    "    \n",
    "    for label in df['label'].unique():\n",
    "        class_data = df[df['label'] == label]\n",
    "        \n",
    "        resampled = resample(class_data,\n",
    "                             replace=False,  \n",
    "                             n_samples= size,  \n",
    "                             random_state=42)\n",
    "        new_df = pd.concat([new_df, resampled])\n",
    "    \n",
    "    \n",
    "    x_train, x_validation, y_train, y_validation = train_test_split(\n",
    "        new_df['review'], new_df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T17:34:39.105662Z",
     "iopub.status.busy": "2025-01-28T17:34:39.105399Z",
     "iopub.status.idle": "2025-01-28T17:34:40.627078Z",
     "shell.execute_reply": "2025-01-28T17:34:40.626484Z",
     "shell.execute_reply.started": "2025-01-28T17:34:39.105643Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('readerbench/RoBERT-base', do_lower_case=True,truncation=True)\n",
    "# tokenizer = BertTokenizer.from_pretrained('readerbench/RoBERT-small', do_lower_case=True,truncation=True)\n",
    "# tokenizer = BertTokenizer.from_pretrained('dumitrescustefan/bert-base-romanian-cased-v1', do_lower_case=True,truncation=True)\n",
    "# tokenizer = BertTokenizer.from_pretrained('snisioi/bert-legal-romanian-cased-v1', do_lower_case=True,truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T17:34:40.628025Z",
     "iopub.status.busy": "2025-01-28T17:34:40.627810Z",
     "iopub.status.idle": "2025-01-28T17:34:58.465880Z",
     "shell.execute_reply": "2025-01-28T17:34:58.465159Z",
     "shell.execute_reply.started": "2025-01-28T17:34:40.628006Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Encode train data using the pretrained tokenizer \n",
    "encoded_x_train = tokenizer.batch_encode_plus(x_train,\n",
    "                    add_special_tokens=True, \n",
    "                    return_attention_mask=True, \n",
    "                    truncation=True,\n",
    "                    padding='longest', \n",
    "                    max_length=512, \n",
    "                    return_tensors='pt')\n",
    "\n",
    "# Encode validation data using the pretrained tokenizer \n",
    "encoded_x_validation = tokenizer.batch_encode_plus(x_validation,\n",
    "                    add_special_tokens=True, \n",
    "                    return_attention_mask=True, \n",
    "                    truncation=True,\n",
    "                    padding='longest', \n",
    "                    max_length=512, \n",
    "                    return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T17:34:58.468459Z",
     "iopub.status.busy": "2025-01-28T17:34:58.468175Z",
     "iopub.status.idle": "2025-01-28T17:34:58.486431Z",
     "shell.execute_reply": "2025-01-28T17:34:58.485626Z",
     "shell.execute_reply.started": "2025-01-28T17:34:58.468437Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Extract input_ids and attention_mask for training\n",
    "input_ids_x_train = encoded_x_train['input_ids']\n",
    "attention_masks_x_train = encoded_x_train['attention_mask']\n",
    "\n",
    "# Convert the labels for training into a torch tensor\n",
    "y_train_vals = torch.tensor(y_train.values)\n",
    "\n",
    "# Extract input_ids and attention_mask for validation\n",
    "input_ids_x_validation = encoded_x_validation['input_ids']\n",
    "attention_masks_x_validation = encoded_x_validation['attention_mask']\n",
    "\n",
    "# Convert the labels for validation into a torch tensor\n",
    "y_validation_vals = torch.tensor(y_validation.values)\n",
    "\n",
    "# Make the train and validation Datasets\n",
    "dataset_train = TensorDataset(input_ids_x_train, attention_masks_x_train, y_train_vals)\n",
    "dataset_validation = TensorDataset(input_ids_x_validation, attention_masks_x_validation, y_validation_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T17:34:58.487788Z",
     "iopub.status.busy": "2025-01-28T17:34:58.487497Z",
     "iopub.status.idle": "2025-01-28T17:35:01.692968Z",
     "shell.execute_reply": "2025-01-28T17:35:01.692363Z",
     "shell.execute_reply.started": "2025-01-28T17:34:58.487757Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the Model\n",
    "model = BertForSequenceClassification.from_pretrained(\"readerbench/RoBERT-base\", num_labels=3, output_attentions=False, output_hidden_states=False)\n",
    "# model = BertForSequenceClassification.from_pretrained(\"reereaderbench/RoBERT-small\", num_labels=3, output_attentions=False, output_hidden_states=False)\n",
    "# model = BertForSequenceClassification.from_pretrained(\"dumitrescustefan/bert-base-romanian-cased-v1\", num_labels=3, output_attentions=False, output_hidden_states=False)\n",
    "# model = BertForSequenceClassification.from_pretrained(\"snisioi/bert-legal-romanian-cased-v1\", num_labels=3, output_attentions=False, output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T17:35:01.698309Z",
     "iopub.status.busy": "2025-01-28T17:35:01.698008Z",
     "iopub.status.idle": "2025-01-28T17:35:02.791970Z",
     "shell.execute_reply": "2025-01-28T17:35:02.791326Z",
     "shell.execute_reply.started": "2025-01-28T17:35:01.698280Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Add balanced weights to make up for the difference in items per class\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',  \n",
    "    classes=[0,1,2], \n",
    "    y=df['label'].to_numpy())\n",
    "\n",
    "# Modify class_weights\n",
    "class_weights_dict = {i: w for i, w in enumerate(class_weights)}\n",
    "# Increase weight for class 1\n",
    "class_weights_dict[1] *= 1.2 \n",
    "# Update weights\n",
    "adjusted_class_weights = np.array([class_weights_dict[0], class_weights_dict[1], class_weights_dict[2]])\n",
    "\n",
    "# Set the device to cuda\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# Set the new weights\n",
    "weight_tensor = torch.tensor(adjusted_class_weights, dtype=torch.float).to(device)\n",
    "print(\"Class weights: \", weight_tensor)\n",
    "\n",
    "# Define loss function with the modified weights\n",
    "loss_function = CrossEntropyLoss(weight = weight_tensor)\n",
    "\n",
    "# Set batch size and number of epochs\n",
    "batch_size = 16\n",
    "epochs = 1\n",
    "\n",
    "# Define seed values\n",
    "seed_value = 123\n",
    "\n",
    "# Define dataloaders for training \n",
    "dataloader_train = DataLoader(dataset_train,sampler=RandomSampler(dataset_train), batch_size=batch_size) \n",
    "dataloader_validation = DataLoader(dataset_validation, sampler=SequentialSampler(dataset_validation), batch_size=batch_size)\n",
    "\n",
    "# Define scheduler\n",
    "optimizer = AdamW(model.parameters(),lr=1e-7, eps=1e-8) \n",
    "train_steps = len(dataloader_train)*epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0,num_training_steps= train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T17:35:02.793187Z",
     "iopub.status.busy": "2025-01-28T17:35:02.792697Z",
     "iopub.status.idle": "2025-01-28T17:35:02.798786Z",
     "shell.execute_reply": "2025-01-28T17:35:02.797993Z",
     "shell.execute_reply.started": "2025-01-28T17:35:02.793162Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def calculate_metrics(predictions, labels):\n",
    "    # Flatten the predictions and ground truths\n",
    "    predictions_flatten = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flatten = labels.flatten()\n",
    "\n",
    "    # Display the Accuracy and Classification Report\n",
    "    print(\"Accuracy: \", metrics.accuracy_score(labels_flatten, predictions_flatten))\n",
    "    print(\"Confusion Matrix:\", metrics.confusion_matrix(labels_flatten, predictions_flatten))\n",
    "    print(\"Classification Report: \", classification_report(labels_flatten, predictions_flatten))\n",
    "\n",
    "    # Define the confusion matrix\n",
    "    confusion_matrix = np.array( metrics.confusion_matrix(labels_flatten, predictions_flatten))\n",
    "    \n",
    "    # Labels for the matrix\n",
    "    classes = ['0', '1', '2']\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(6, 5))  \n",
    "    sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"RdYlBu\", \n",
    "                xticklabels=classes, yticklabels=classes, cbar=True, annot_kws={\"size\": 15})\n",
    "    \n",
    "    # Add labels, title, and adjust formatting\n",
    "    plt.xlabel(\"Predicted\", fontsize=12)  \n",
    "    plt.ylabel(\"True\", fontsize=12)  \n",
    "    plt.title(\"Confusion Matrix\", fontsize=14)  \n",
    "    \n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T17:35:02.799744Z",
     "iopub.status.busy": "2025-01-28T17:35:02.799489Z",
     "iopub.status.idle": "2025-01-28T17:35:02.819753Z",
     "shell.execute_reply": "2025-01-28T17:35:02.818932Z",
     "shell.execute_reply.started": "2025-01-28T17:35:02.799714Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(data):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Define predictions and ground truths \n",
    "    predictions, ground_truth = [], []\n",
    "    # Define total loss\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Define batch evaluation using the dataloader \n",
    "    for batch in data:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2]}\n",
    "\n",
    "        # Extract the ground truth values\n",
    "        ground_truth.append(inputs['labels'].cpu().numpy())\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        # Extract and predict the loss\n",
    "        loss = outputs[0]\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Extract and update the predicted values\n",
    "        logits = outputs[1]\n",
    "        predictions.append(logits.cpu().numpy())\n",
    "        \n",
    "    # Calculate the average loss\n",
    "    average_loss = total_loss/len(data) \n",
    "\n",
    "    # Concatenate predictions\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    # Concatenate ground truth values\n",
    "    ground_truth = np.concatenate(ground_truth, axis=0)\n",
    "            \n",
    "    return average_loss, predictions, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T17:41:46.334491Z",
     "iopub.status.busy": "2025-01-28T17:41:46.334146Z",
     "iopub.status.idle": "2025-01-28T17:41:46.342297Z",
     "shell.execute_reply": "2025-01-28T17:41:46.341393Z",
     "shell.execute_reply.started": "2025-01-28T17:41:46.334466Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(data, best_loss):\n",
    "    for epoch in tqdm(range(1, epochs+1)):\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        # Define total train loss\n",
    "        total_loss = 0\n",
    "    \n",
    "        progress_bar = tqdm(data, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "        for batch in progress_bar:\n",
    "    \n",
    "            model.zero_grad()\n",
    "            \n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            \n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'labels':         batch[2],\n",
    "                     }       \n",
    "    \n",
    "            # Extract the labels\n",
    "            labels = inputs['labels']\n",
    "            \n",
    "            outputs = model(**inputs)\n",
    "    \n",
    "            # Extract the predicted values\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            # Calculate loss and update the total train loss \n",
    "            loss = loss_function(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "            # Back propagate the loss\n",
    "            loss.backward()\n",
    "    \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "    \n",
    "        # Save the current Model\n",
    "        torch.save(model.state_dict(), f'models/ROBERT_base_{epoch}.model')\n",
    "            \n",
    "        tqdm.write(f'\\nEpoch: {epoch}')\n",
    "    \n",
    "        # Calculate Average training Loss\n",
    "        average_loss = total_loss/len(data)            \n",
    "    \n",
    "        # Evaluate the Validation Data\n",
    "        validation_loss, predictions, ground_truth = evaluate(dataloader_validation)\n",
    "    \n",
    "        # Calculate the F1-Score\n",
    "        predictions_flatten = np.argmax(predictions, axis=1).flatten()\n",
    "        gt_flatten = ground_truth.flatten()\n",
    "        validation_f1_score = f1_score(gt_flatten, predictions_flatten, average='weighted')\n",
    "\n",
    "        # Write the Losses for this epoch\n",
    "        tqdm.write(f'Train Loss: {average_loss}, Validation Loss: {validation_loss}, Validation F1-Score: {validation_f1_score}')\n",
    "        \n",
    "        # Check for Early Stopping \n",
    "        if validation_loss < best_loss:\n",
    "            best_loss = validation_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "        \n",
    "        if counter >= no_epochs:\n",
    "            print(\"Early stopping.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T17:41:36.238512Z",
     "iopub.status.busy": "2025-01-28T17:41:36.238203Z",
     "iopub.status.idle": "2025-01-28T17:41:36.248312Z",
     "shell.execute_reply": "2025-01-28T17:41:36.247607Z",
     "shell.execute_reply.started": "2025-01-28T17:41:36.238491Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set the model to cuda\n",
    "model.to(device)\n",
    "\n",
    "# Create directory to save the models at every epoch\n",
    "Path('/kaggle/working/models/').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Implement early stopping\n",
    "no_epochs = 5 # Wait for 5 epochs\n",
    "best_loss = np.inf \n",
    "counter = 0\n",
    "\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed_all(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T17:41:49.468501Z",
     "iopub.status.busy": "2025-01-28T17:41:49.468159Z",
     "iopub.status.idle": "2025-01-28T17:46:41.157433Z",
     "shell.execute_reply": "2025-01-28T17:46:41.156443Z",
     "shell.execute_reply.started": "2025-01-28T17:41:49.468476Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "train(dataloader_train, best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T17:47:33.610769Z",
     "iopub.status.busy": "2025-01-28T17:47:33.610471Z",
     "iopub.status.idle": "2025-01-28T17:47:52.561696Z",
     "shell.execute_reply": "2025-01-28T17:47:52.560836Z",
     "shell.execute_reply.started": "2025-01-28T17:47:33.610747Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluate and display Accuracy, Confusion Matrix and Classification Report\n",
    "_, predictions, labels= evaluate(dataloader_validation)\n",
    "calculate_metrics(predictions, labels)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6481169,
     "sourceId": 10467826,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 221904,
     "modelInstanceId": 200085,
     "sourceId": 234254,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 222114,
     "modelInstanceId": 200297,
     "sourceId": 234487,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 222123,
     "modelInstanceId": 200305,
     "sourceId": 234496,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 222139,
     "modelInstanceId": 200321,
     "sourceId": 234515,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
